{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluating_Multiclass_Classifiers_Textanalytics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chain-veerender/veerender/blob/master/Evaluating_Multiclass_Classifiers_Textanalytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zA7X-ZQoNKWb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Motivation for Session:\n",
        " \n",
        " What ML model should I use for given Problem?\n",
        " \n",
        " Too Many Parameters exists to tune, when and where do we tune these so called hyper parameters?\n",
        " \n",
        " How do we interact with Data and Analyze?\n",
        " \n",
        " Nobody can tell answer based on intutions...Happy Experimenting...."
      ]
    },
    {
      "metadata": {
        "id": "2OTlBXdXOhEH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1) Loading All Necessary packages:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xkaC_0HMP_d0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Loading Basic Packages\n",
        "\n",
        "from __future__ import print_function                #To ensure that future statements run under releases prior to 3 at least yield runtime exceptions\n",
        "\n",
        "import logging                                       #defines functions and classes which implement a flexible event logging system for applications and libraries.\n",
        "import numpy as np                                   #fundamental package for scientific computing with Python\n",
        "from optparse import OptionParser                     #(earlier version of python, now depreceated)\n",
        "#from argparse import ArgumentParser                  # Parser for command-line options, arguments and sub-commands\n",
        "import sys                                           #System-specific parameters and functions\n",
        "from time import time                                #Time access and conversions\n",
        "import matplotlib.pyplot as plt                      # plots and visualizations\n",
        "import pandas as pd                                  # Data Analysis Library\n",
        "from numpy import random                             # pseudo-random number generators for various distributions\n",
        "\n",
        "## Loading packages for Pre-processing\n",
        "import gensim                                       # Analyze plain-text documents for semantic structure\n",
        "import nltk                                         # library to play with natural language\n",
        "from nltk.corpus import stopwords                   # Common words not useful for building model\n",
        "import re                                           #  provides regular expression matching operations\n",
        "from bs4 import BeautifulSoup                       #  Python library for pulling data out of HTML and XML files\n",
        "\n",
        "## Loading Dataset (In general, CSV or Sql file must be loaded)\n",
        "from sklearn.datasets import fetch_20newsgroups                          # To avoid Headache of Uploading in colab, working on scikit learn available dataset\n",
        "\n",
        "## Feature Extraction and selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer  # Bag of words, tfidf vect, hashing for large corpus\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "#from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.decomposition import PCA               # Dimensionality Reduction\n",
        "\n",
        "## For comupting Pdfs\n",
        "from sklearn.utils.extmath import density            # Compute density of a sparse vector\n",
        "\n",
        "## Evaluation Metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "## Transforms and fitting\n",
        "from sklearn.pipeline import Pipeline               # implement fit and transform methods\n",
        "\n",
        "## Classifiers (Few picked for evaluation)\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "#from sklearn.linear_model import Perceptron\n",
        "#from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bcnnagEhCftV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##2) Exploring Data "
      ]
    },
    {
      "metadata": {
        "id": "0E5nFIQFC_AI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Display progress logs on stdout\n",
        "logging.basicConfig(level=logging.INFO,\n",
        "                    format='%(asctime)s %(levelname)s %(message)s')\n",
        "\n",
        "# parse commandline arguments\n",
        "op = OptionParser()\n",
        "op.add_option(\"--report\",\n",
        "              action=\"store_true\", dest=\"print_report\",\n",
        "              help=\"Print a detailed classification report.\")\n",
        "op.add_option(\"--chi2_select\",\n",
        "              action=\"store\", type=\"int\", dest=\"select_chi2\",\n",
        "              help=\"Select some number of features using a chi-squared test\")\n",
        "op.add_option(\"--confusion_matrix\",\n",
        "              action=\"store_true\", dest=\"print_cm\",\n",
        "              help=\"Print the confusion matrix.\")\n",
        "op.add_option(\"--top10\",\n",
        "              action=\"store_true\", dest=\"print_top10\",\n",
        "              help=\"Print ten most discriminative terms per class\"\n",
        "                   \" for every classifier.\")\n",
        "op.add_option(\"--all_categories\",\n",
        "              action=\"store_true\", dest=\"all_categories\",\n",
        "              help=\"Whether to use all categories or not.\")\n",
        "op.add_option(\"--use_hashing\",\n",
        "              action=\"store_true\",\n",
        "              help=\"Use a hashing vectorizer.\")\n",
        "op.add_option(\"--n_features\",\n",
        "              action=\"store\", type=int, default=2 ** 16,\n",
        "              help=\"n_features when using the hashing vectorizer.\")\n",
        "op.add_option(\"--filtered\",\n",
        "              action=\"store_true\",\n",
        "              help=\"Remove newsgroup information that is easily overfit: \"\n",
        "                   \"headers, signatures, and quoting.\")\n",
        "\n",
        "\n",
        "def is_interactive():\n",
        "    return not hasattr(sys.modules['__main__'], '__file__')\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KlnksE24-9nc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "236b8c0c-157c-49d5-b02b-4866db301776"
      },
      "cell_type": "code",
      "source": [
        "# work-around for Jupyter notebook and IPython console\n",
        "argv = [] if is_interactive() else sys.argv[1:]\n",
        "(opts, args) = op.parse_args(argv)\n",
        "if len(args) > 0:\n",
        "    op.error(\"this script takes no arguments.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(__doc__)\n",
        "op.print_help()\n",
        "print()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Automatically created module for IPython interactive environment\n",
            "Usage: ipykernel_launcher.py [options]\n",
            "\n",
            "Options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --report              Print a detailed classification report.\n",
            "  --chi2_select=SELECT_CHI2\n",
            "                        Select some number of features using a chi-squared\n",
            "                        test\n",
            "  --confusion_matrix    Print the confusion matrix.\n",
            "  --top10               Print ten most discriminative terms per class for\n",
            "                        every classifier.\n",
            "  --all_categories      Whether to use all categories or not.\n",
            "  --use_hashing         Use a hashing vectorizer.\n",
            "  --n_features=N_FEATURES\n",
            "                        n_features when using the hashing vectorizer.\n",
            "  --filtered            Remove newsgroup information that is easily overfit:\n",
            "                        headers, signatures, and quoting.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OMRkfkDX_UEk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "929251d4-5440-4da7-d88a-3312947d03b4"
      },
      "cell_type": "code",
      "source": [
        "# #############################################################################\n",
        "# Load some categories from the training set\n",
        "if opts.all_categories:\n",
        "    categories = None\n",
        "else:\n",
        "    categories = [\n",
        "        'alt.atheism',\n",
        "        'talk.religion.misc',\n",
        "        'comp.graphics',\n",
        "        'sci.space',\n",
        "    ]\n",
        "\n",
        "if opts.filtered:\n",
        "    remove = ('headers', 'footers', 'quotes')\n",
        "else:\n",
        "    remove = ()\n",
        "\n",
        "print(\"Loading 20 newsgroups dataset for categories:\")\n",
        "print(categories if categories else \"all\")\n",
        "\n",
        "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
        "                                shuffle=True, random_state=42,\n",
        "                                remove=remove)\n",
        "\n",
        "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
        "                               shuffle=True, random_state=42,\n",
        "                               remove=remove)\n",
        "print('data loaded')\n",
        "\n",
        "# order of labels in `target_names` can be different from `categories`\n",
        "target_names = data_train.target_names\n",
        "\n",
        "\n",
        "def size_mb(docs):\n",
        "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
        "\n",
        "\n",
        "data_train_size_mb = size_mb(data_train.data)\n",
        "data_test_size_mb = size_mb(data_test.data)\n",
        "\n",
        "print(\"%d documents - %0.3fMB (training set)\" % (\n",
        "    len(data_train.data), data_train_size_mb))\n",
        "print(\"%d documents - %0.3fMB (test set)\" % (\n",
        "    len(data_test.data), data_test_size_mb))\n",
        "print(\"%d categories\" % len(target_names))\n",
        "print()\n",
        "\n",
        "# split a training set and a test set\n",
        "y_train, y_test = data_train.target, data_test.target\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "2019-04-15 12:35:19,214 INFO Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n",
            "2019-04-15 12:35:19,219 INFO Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading 20 newsgroups dataset for categories:\n",
            "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
            "data loaded\n",
            "2034 documents - 3.980MB (training set)\n",
            "1353 documents - 2.867MB (test set)\n",
            "4 categories\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nSYTeDak_vDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "6347a7d2-ce97-4651-a0ee-491a9c01a42a"
      },
      "cell_type": "code",
      "source": [
        "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
        "t0 = time()\n",
        "if opts.use_hashing:\n",
        "    vectorizer = HashingVectorizer(stop_words='english', alternate_sign=False,\n",
        "                                   n_features=opts.n_features)\n",
        "    X_train = vectorizer.transform(data_train.data)\n",
        "else:\n",
        "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
        "                                 stop_words='english')\n",
        "    X_train = vectorizer.fit_transform(data_train.data)\n",
        "duration = time() - t0\n",
        "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
        "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
        "print()\n",
        "\n",
        "print(\"Extracting features from the test data using the same vectorizer\")\n",
        "t0 = time()\n",
        "X_test = vectorizer.transform(data_test.data)\n",
        "duration = time() - t0\n",
        "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
        "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
        "print()\n",
        "\n",
        "# mapping from integer feature name to original token string\n",
        "if opts.use_hashing:\n",
        "    feature_names = None\n",
        "else:\n",
        "    feature_names = vectorizer.get_feature_names()\n",
        "\n",
        "if opts.select_chi2:\n",
        "    print(\"Extracting %d best features by a chi-squared test\" %\n",
        "          opts.select_chi2)\n",
        "    t0 = time()\n",
        "    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
        "    X_train = ch2.fit_transform(X_train, y_train)\n",
        "    X_test = ch2.transform(X_test)\n",
        "    if feature_names:\n",
        "        # keep selected feature names\n",
        "        feature_names = [feature_names[i] for i\n",
        "                         in ch2.get_support(indices=True)]\n",
        "    print(\"done in %fs\" % (time() - t0))\n",
        "    print()\n",
        "\n",
        "if feature_names:\n",
        "    feature_names = np.asarray(feature_names)\n",
        "\n",
        "\n",
        "def trim(s):\n",
        "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
        "    return s if len(s) <= 80 else s[:77] + \"...\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting features from the training data using a sparse vectorizer\n",
            "done in 0.636855s at 6.249MB/s\n",
            "n_samples: 2034, n_features: 33809\n",
            "\n",
            "Extracting features from the test data using the same vectorizer\n",
            "done in 0.364372s at 7.870MB/s\n",
            "n_samples: 1353, n_features: 33809\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VG88DO1oACmQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3485
        },
        "outputId": "07d53d02-ff7c-4d37-b7e9-6882618f2f18"
      },
      "cell_type": "code",
      "source": [
        "# #############################################################################\n",
        "# Benchmark classifiers\n",
        "def benchmark(clf):\n",
        "    print('_' * 80)\n",
        "    print(\"Training: \")\n",
        "    print(clf)\n",
        "    t0 = time()\n",
        "    clf.fit(X_train, y_train)\n",
        "    train_time = time() - t0\n",
        "    print(\"train time: %0.3fs\" % train_time)\n",
        "\n",
        "    t0 = time()\n",
        "    pred = clf.predict(X_test)\n",
        "    test_time = time() - t0\n",
        "    print(\"test time:  %0.3fs\" % test_time)\n",
        "\n",
        "    score = metrics.accuracy_score(y_test, pred)\n",
        "    print(\"accuracy:   %0.3f\" % score)\n",
        "\n",
        "    if hasattr(clf, 'coef_'):\n",
        "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
        "        print(\"density: %f\" % density(clf.coef_))\n",
        "\n",
        "        if opts.print_top10 and feature_names is not None:\n",
        "            print(\"top 10 keywords per class:\")\n",
        "            for i, label in enumerate(target_names):\n",
        "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
        "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
        "        print()\n",
        "\n",
        "    if opts.print_report:\n",
        "        print(\"classification report:\")\n",
        "        print(metrics.classification_report(y_test, pred,\n",
        "                                            target_names=target_names))\n",
        "\n",
        "    if opts.print_cm:\n",
        "        print(\"confusion matrix:\")\n",
        "        print(metrics.confusion_matrix(y_test, pred))\n",
        "\n",
        "    print()\n",
        "    clf_descr = str(clf).split('(')[0]\n",
        "    return clf_descr, score, train_time, test_time\n",
        "\n",
        "\n",
        "results = []\n",
        "for clf, name in (\n",
        "        (RidgeClassifier(tol=1e-2, solver=\"sag\"), \"Ridge Classifier\"),\n",
        "        #(Perceptron(max_iter=50, tol=1e-3), \"Perceptron\"),\n",
        "        #(PassiveAggressiveClassifier(max_iter=50, tol=1e-3),\n",
        "         #\"Passive-Aggressive\"),#\n",
        "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
        "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
        "    print('=' * 80)\n",
        "    print(name)\n",
        "    results.append(benchmark(clf))\n",
        "\n",
        "for penalty in [\"l2\", \"l1\"]:\n",
        "    print('=' * 80)\n",
        "    print(\"%s penalty\" % penalty.upper())\n",
        "    # Train Liblinear model\n",
        "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n",
        "                                       tol=1e-3)))\n",
        "\n",
        "    # Train SGD model\n",
        "    results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n",
        "                                           penalty=penalty)))\n",
        "\n",
        "# Train SGD with Elastic Net penalty\n",
        "print('=' * 80)\n",
        "print(\"Elastic-Net penalty\")\n",
        "results.append(benchmark(SGDClassifier(alpha=.0001, max_iter=50,\n",
        "                                       penalty=\"elasticnet\")))\n",
        "\n",
        "# Train NearestCentroid without threshold\n",
        "print('=' * 80)\n",
        "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
        "results.append(benchmark(NearestCentroid()))\n",
        "\n",
        "# Train sparse Naive Bayes classifiers\n",
        "print('=' * 80)\n",
        "print(\"Naive Bayes\")\n",
        "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
        "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
        "#results.append(benchmark(ComplementNB(alpha=.1)))\n",
        "\n",
        "print('=' * 80)\n",
        "print(\"LinearSVC with L1-based feature selection\")\n",
        "# The smaller C, the stronger the regularization.\n",
        "# The more regularization, the more sparsity.\n",
        "results.append(benchmark(Pipeline([\n",
        "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
        "                                                  tol=1e-3))),\n",
        "  ('classification', LinearSVC(penalty=\"l2\"))])))\n",
        "\n",
        "# make some plots\n",
        "\n",
        "indices = np.arange(len(results))\n",
        "\n",
        "results = [[x[i] for x in results] for i in range(4)]\n",
        "\n",
        "clf_names, score, training_time, test_time = results\n",
        "training_time = np.array(training_time) / np.max(training_time)\n",
        "test_time = np.array(test_time) / np.max(test_time)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.title(\"Score\")\n",
        "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
        "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
        "         color='c')\n",
        "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
        "plt.yticks(())\n",
        "plt.legend(loc='best')\n",
        "plt.subplots_adjust(left=.25)\n",
        "plt.subplots_adjust(top=.95)\n",
        "plt.subplots_adjust(bottom=.05)\n",
        "\n",
        "for i, c in zip(indices, clf_names):\n",
        "    plt.text(-.3, i, c)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "Ridge Classifier\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
            "        max_iter=None, normalize=False, random_state=None, solver='sag',\n",
            "        tol=0.01)\n",
            "train time: 0.317s\n",
            "test time:  0.002s\n",
            "accuracy:   0.897\n",
            "dimensionality: 33809\n",
            "density: 1.000000\n",
            "\n",
            "\n",
            "================================================================================\n",
            "kNN\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
            "           weights='uniform')\n",
            "train time: 0.002s\n",
            "test time:  0.247s\n",
            "accuracy:   0.858\n",
            "\n",
            "================================================================================\n",
            "Random forest\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False)\n",
            "train time: 2.044s\n",
            "test time:  0.107s\n",
            "accuracy:   0.840\n",
            "\n",
            "================================================================================\n",
            "L2 penalty\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
            "     verbose=0)\n",
            "train time: 0.229s\n",
            "test time:  0.002s\n",
            "accuracy:   0.900\n",
            "dimensionality: 33809\n",
            "density: 1.000000\n",
            "\n",
            "\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
            "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
            "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
            "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
            "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
            "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "train time: 0.131s\n",
            "test time:  0.003s\n",
            "accuracy:   0.901\n",
            "dimensionality: 33809\n",
            "density: 0.666391\n",
            "\n",
            "\n",
            "================================================================================\n",
            "L1 penalty\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
            "     verbose=0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train time: 0.279s\n",
            "test time:  0.002s\n",
            "accuracy:   0.873\n",
            "dimensionality: 33809\n",
            "density: 0.005553\n",
            "\n",
            "\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
            "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
            "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
            "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l1',\n",
            "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
            "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "train time: 0.511s\n",
            "test time:  0.003s\n",
            "accuracy:   0.884\n",
            "dimensionality: 33809\n",
            "density: 0.020305\n",
            "\n",
            "\n",
            "================================================================================\n",
            "Elastic-Net penalty\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
            "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
            "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=50,\n",
            "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='elasticnet',\n",
            "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
            "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "train time: 0.696s\n",
            "test time:  0.003s\n",
            "accuracy:   0.898\n",
            "dimensionality: 33809\n",
            "density: 0.187273\n",
            "\n",
            "\n",
            "================================================================================\n",
            "NearestCentroid (aka Rocchio classifier)\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
            "train time: 0.014s\n",
            "test time:  0.003s\n",
            "accuracy:   0.855\n",
            "\n",
            "================================================================================\n",
            "Naive Bayes\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "train time: 0.009s\n",
            "test time:  0.002s\n",
            "accuracy:   0.899\n",
            "dimensionality: 33809\n",
            "density: 1.000000\n",
            "\n",
            "\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
            "train time: 0.011s\n",
            "test time:  0.010s\n",
            "accuracy:   0.884\n",
            "dimensionality: 33809\n",
            "density: 1.000000\n",
            "\n",
            "\n",
            "================================================================================\n",
            "LinearSVC with L1-based feature selection\n",
            "________________________________________________________________________________\n",
            "Training: \n",
            "Pipeline(memory=None,\n",
            "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
            "     verbose=0),\n",
            "        max_features=None, no...ax_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0))])\n",
            "train time: 0.350s\n",
            "test time:  0.005s\n",
            "accuracy:   0.879\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "iLYMQg7LBU7s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py\n",
        "\n",
        "https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
        "\n",
        "https://github.com/RaRe-Technologies/movie-plots-by-genre/blob/master/ipynb_with_output/Document%20classification%20with%20word%20embeddings%20tutorial%20-%20with%20output.ipynb\n",
        "\n",
        "https://github.com/tensorflow/workshops/blob/master/extras/keras-bag-of-words/keras-bow-model.ipynb\n",
        "\n",
        "https://datascience.stackexchange.com/questions/20076/word2vec-vs-sentence2vec-vs-doc2vec\n"
      ]
    }
  ]
}