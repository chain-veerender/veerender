{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluating_Multiclass_Classifiers_Textanalytics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chain-veerender/veerender/blob/master/Evaluating_Multiclass_Classifiers_Textanalytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zA7X-ZQoNKWb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Motivation for Session:\n",
        " \n",
        " What ML model should I use for given Problem?\n",
        " \n",
        " Too Many Parameters exists to tune, when and where do we tune these so called hyper parameters?\n",
        " \n",
        " How do we interact with Data and Analyze?\n",
        " \n",
        " Nobody can tell answer based on intutions...Happy Experimenting...."
      ]
    },
    {
      "metadata": {
        "id": "2OTlBXdXOhEH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##1) Loading All Necessary packages:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xkaC_0HMP_d0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Loading Basic Packages\n",
        "\n",
        "from __future__ import print_function                #To ensure that future statements run under releases prior to 3 at least yield runtime exceptions\n",
        "\n",
        "import logging                                       #defines functions and classes which implement a flexible event logging system for applications and libraries.\n",
        "import numpy as np                                   #fundamental package for scientific computing with Python\n",
        "#from optparse import OptionParser   (earlier version of python, now depreceated)\n",
        "from argparse import ArgumentParser                  # Parser for command-line options, arguments and sub-commands\n",
        "import sys                                           #System-specific parameters and functions\n",
        "from time import time                                #Time access and conversions\n",
        "import matplotlib.pyplot as plt                      # plots and visualizations\n",
        "import pandas as pd                                  # Data Analysis Library\n",
        "from numpy import random                             # pseudo-random number generators for various distributions\n",
        "\n",
        "## Loading packages for Pre-processing\n",
        "import gensim                                       # Analyze plain-text documents for semantic structure\n",
        "import nltk                                         # library to play with natural language\n",
        "from nltk.corpus import stopwords                   # Common words not useful for building model\n",
        "import re                                           #  provides regular expression matching operations\n",
        "from bs4 import BeautifulSoup                       #  Python library for pulling data out of HTML and XML files\n",
        "\n",
        "## Loading Dataset (In general, CSV or Sql file must be loaded)\n",
        "from sklearn.datasets import fetch_20newsgroups                          # To avoid Headache of Uploading in colab, working on scikit learn available dataset\n",
        "\n",
        "## Feature Extraction and selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer  # Bag of words, tfidf vect, hashing for large corpus\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "#from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.decomposition import PCA               # Dimensionality Reduction\n",
        "\n",
        "## For comupting Pdfs\n",
        "from sklearn.utils.extmath import density            # Compute density of a sparse vector\n",
        "\n",
        "## Evaluation Metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "## Transforms and fitting\n",
        "from sklearn.pipeline import Pipeline               # implement fit and transform methods\n",
        "\n",
        "## Classifiers (Few picked for evaluation)\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "#from sklearn.linear_model import Perceptron\n",
        "#from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bcnnagEhCftV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##2) Exploring Data "
      ]
    },
    {
      "metadata": {
        "id": "0E5nFIQFC_AI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "0543fc52-0cc1-4ff5-d48f-894296d93c12"
      },
      "cell_type": "code",
      "source": [
        "arg = ArgumentParser()\n",
        "arg.add_argument('all_categories',\n",
        "                  action='store_true',\n",
        "\n",
        "               help='Whether to use all categories or not.')\n",
        "\n",
        "def is_interactive():\n",
        "    return not hasattr(sys.modules['__main__'], '__file__')\n",
        "\n",
        "# work-around for Jupyter notebook and IPython console\n",
        "argv = [] if is_interactive() else sys.argv[1:]\n",
        "args = arg.parse_args(argv)\n",
        "'''if len(args) > 0:\n",
        "    arg.error(\"this script takes no arguments.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(__doc__)\n",
        "arg.print_help()\n",
        "print() '''\n",
        "\n",
        "if all_categories:\n",
        "    categories = None\n",
        "else:\n",
        "    categories = [\n",
        "        'alt.atheism',\n",
        "        'talk.religion.misc',\n",
        "        'comp.graphics',\n",
        "        'sci.space',\n",
        "    ]\n",
        "\n",
        "print(categories if categories else \"all\")\n",
        "\n",
        "categ_20 = fetch_20newsgroups(categories = categories)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-d7061b891a7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m print() '''\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mall_categories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_categories' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "TvsPqRh-Minv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "c5fa90b1-81a3-42ab-db0f-425f88a2f6ab"
      },
      "cell_type": "code",
      "source": [
        "print(categ_20)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8fV7ZRfZM46b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "69aa2999-3d78-4c12-9887-f3ff405427b2"
      },
      "cell_type": "code",
      "source": [
        "print(categ_20.apply(lambda x: len(x.split(' '))).sum())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'apply'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-254004b30e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcateg_20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: apply"
          ]
        }
      ]
    }
  ]
}
